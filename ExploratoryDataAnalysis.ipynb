{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExploratoryDataAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0ubFjzL0LNErLNm329eV9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2qi1GH8zZYx"
      },
      "source": [
        "# Utilitários"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-4JvSzJRgn2"
      },
      "source": [
        "## Copia arquivo para servidor remoto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j8jpOfjVPHB"
      },
      "source": [
        "### Instala sshpass para passar a senha para o scp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoajCDtCRrke"
      },
      "source": [
        "!apt install sshpass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWu9Dl9_V6SW"
      },
      "source": [
        "### Executa scp para copiar arquivo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZuqs589ViRP"
      },
      "source": [
        "user = \"\"\n",
        "senha = \"\"\n",
        "host = \"rafaelescalfoni.net\"\n",
        "file = \"prefeito_rio_2020_pt.csv\"\n",
        "# Executa comando no bash\n",
        "!sshpass -p $senha scp -o 'StrictHostKeyChecking no' $file $user@$host:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrGHjBZORa_Q"
      },
      "source": [
        "# Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYpMrUpGzWiF"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "import re\n",
        "# Imports individuais\n",
        "from pandas.core.frame import DataFrame\n",
        "from nltk import tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "# NLTK corpora\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DXdghqxcUJZ"
      },
      "source": [
        "# Abre o DataSet diretamente da internet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL-NAQyWXtoe"
      },
      "source": [
        "Desabilita verificação SSL em caso de certificado auto-assinado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO2stlAWUfX1"
      },
      "source": [
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvHOGwd0UlnF"
      },
      "source": [
        "Lê o Dataset Original:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekyUKGGh8f2j"
      },
      "source": [
        "url = \"https://rafaelescalfoni.net/prefeito_rio_2020.csv\"\n",
        "ds = pd.read_csv(url)\n",
        "ds.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SctrRPTQbcJK"
      },
      "source": [
        "Lê o Dataset Limpo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV05itjOiXOk"
      },
      "source": [
        "url = \"https://rafaelescalfoni.net/prefeito_rio_2020_clean.csv\"\n",
        "# Parâmetro \"na_filter\" usado para lidar com campos nulos como string\n",
        "ds = pd.read_csv(url, na_filter=False)\n",
        "ds.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBaFU05Lu3-r"
      },
      "source": [
        "Lê o Dataset com Texto Processado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i28R3J1vHYr"
      },
      "source": [
        "url = \"https://rafaelescalfoni.net/prefeito_rio_2020_pt.csv\"\n",
        "# Parâmetro \"na_filter\" usado para lidar com campos nulos como string\n",
        "ds_por = pd.read_csv(url, index_col=0, na_filter=False)\n",
        "ds_por.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bOvTFne3UMe"
      },
      "source": [
        "# Limpeza de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLxIk0iFbN7F"
      },
      "source": [
        "## Eliminação de colunas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNQrtXlqbYHc"
      },
      "source": [
        "### Função para eliminar colunas com taxa de nulos acima do limite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGC_hPsNRiYd"
      },
      "source": [
        "def drop_column_null_above_limit(df: DataFrame, ignored_columns=[], threshold=0.8):\n",
        "  columns = df.columns.drop(ignored_columns)\n",
        "  # Pega colunas acima do limite de null, exceto as ignoradas\n",
        "  columns = [column for column in columns if df[column].isna().sum()/df.shape[0] > threshold]\n",
        "\n",
        "  return df.drop(columns, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9hyRVfCby-u"
      },
      "source": [
        "### Elimina colunas com alta taxa de nulos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LZ0DOGMWqa8"
      },
      "source": [
        "# Resguarda coluna \"extended_tweet\" de eliminação por conta da análise de sentimento\n",
        "ds = drop_column_null_above_limit(ds, ['extended_tweet'])\n",
        "ds.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp-2t9C6_bBC"
      },
      "source": [
        "### Função para eliminar colunas com um único valor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvpHTSZn_kAV"
      },
      "source": [
        "def drop_column_unique_value(df: DataFrame):\n",
        "  # Pega colunas com um único valor\n",
        "  columns = [column for column in df.columns if df[column].nunique() == 1]\n",
        "\n",
        "  return df.drop(columns, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7YeQXzuCYYT"
      },
      "source": [
        "### Elimina colunas com um único valor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVxVyV8ADqQe"
      },
      "source": [
        "ds = drop_column_unique_value(ds)\n",
        "ds.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdoaZEDeE730"
      },
      "source": [
        "### Elimina as colunas que não têm utilidade para nossa análise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGQ3YO_x4xAU"
      },
      "source": [
        "ignored_columns = ['_id', 'id_str']\n",
        "ds.drop(columns=ignored_columns, inplace=True)\n",
        "ds.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZCZ-qsjc3CR"
      },
      "source": [
        "## Tratamento das colunas JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX14MZtAO_qx"
      },
      "source": [
        "### Função para converter listas para string JSON no DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1zmH8yqiVfO"
      },
      "source": [
        "def converte_lista_json(df: DataFrame):\n",
        "  for column in df.columns:\n",
        "    df[column] = df[column].apply(lambda x: json.dumps(x) if type(x) == list else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7_QE3po3Mgu"
      },
      "source": [
        "### Lista colunas com objetos JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_HkwduOarys"
      },
      "source": [
        "# Função que verifica se determinada string é um objeto json (parâmetro opcional = somente dicionário)\n",
        "def is_json(myjson, ignore_list=True):\n",
        "  try:\n",
        "    json_object = json.loads(myjson)\n",
        "  except:\n",
        "    return False\n",
        "  # Verifica se o objeto json é uma lista\n",
        "  if (ignore_list and type(json_object) == list):\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "# Analisa sempre o primeiro índice não nulo da referida coluna, ou 0 quando a coluna é vazia\n",
        "[column for column in ds.columns if is_json(ds[column][ds[column].first_valid_index() or 0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0vw3jM7nidm"
      },
      "source": [
        "### Expandir colunas JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHMg7derP3Ej"
      },
      "source": [
        "#### Coluna user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtA5yXnpRzQ0"
      },
      "source": [
        "Transforma os objetos JSON da coluna em um DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTNJw6XXSvlU"
      },
      "source": [
        "expanded_user = pd.json_normalize(ds.user.apply(json.loads))\n",
        "expanded_user.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0ma7fvarN2D"
      },
      "source": [
        "Elimina colunas com alta taxa de nulos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s75P7aXmrewG"
      },
      "source": [
        "expanded_user = drop_column_null_above_limit(expanded_user)\n",
        "expanded_user.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHGPpaFAGQh_"
      },
      "source": [
        "Elimina colunas com um único valor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1KWgn3BGixq"
      },
      "source": [
        "expanded_user = drop_column_unique_value(expanded_user)\n",
        "expanded_user.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G2Os4OUHCaC"
      },
      "source": [
        "Elimina as colunas que não têm utilidade para nossa análise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8PzYP1rHNBq"
      },
      "source": [
        "ignored_columns = ['id', 'url', 'translator_type', 'profile_background_color', 'profile_background_image_url', 'profile_background_image_url_https',\n",
        "                   'profile_background_tile', 'profile_link_color', 'profile_sidebar_border_color', 'profile_sidebar_fill_color', 'profile_text_color',\n",
        "                   'profile_use_background_image', 'profile_image_url', 'profile_image_url_https', 'profile_banner_url', 'default_profile', 'id.$numberLong']\n",
        "expanded_user.drop(columns=ignored_columns, inplace=True)\n",
        "expanded_user.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtY0bo7grtJC"
      },
      "source": [
        "#### Coluna extended_tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEF4261zUWtH"
      },
      "source": [
        "Transforma os objetos JSON da coluna em um DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK4Q5girbovj"
      },
      "source": [
        "# Transforma dados null em objetos json vazio {} antes de carregar\n",
        "expanded_ext_tweet = pd.json_normalize(ds.extended_tweet.fillna('{}').apply(json.loads))\n",
        "expanded_ext_tweet.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOhJOq8Jsazl"
      },
      "source": [
        "Elimina colunas com alta taxa de nulos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TI1a874sgE1"
      },
      "source": [
        "# Resguarda colunas de eliminação por conta de análises\n",
        "expanded_ext_tweet = drop_column_null_above_limit(expanded_ext_tweet, ['full_text', 'entities.hashtags', 'entities.urls', 'entities.user_mentions'])\n",
        "expanded_ext_tweet.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXybTCJ3uSuW"
      },
      "source": [
        "Converte colunas contendo listas em representações string de objetos JSON:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzttj6nOuY_X"
      },
      "source": [
        "converte_lista_json(expanded_ext_tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvStRa7iRFpY"
      },
      "source": [
        "#### Coluna entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTSdhV8tUZ6I"
      },
      "source": [
        "Transforma os objetos JSON da coluna em um DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJuhuG77iJwu"
      },
      "source": [
        "expanded_entities = pd.json_normalize(ds.entities.apply(json.loads))\n",
        "expanded_entities.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWPsIwQutakl"
      },
      "source": [
        "Elimina colunas com alta taxa de nulos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clRDOqDCthh7"
      },
      "source": [
        "expanded_entities = drop_column_null_above_limit(expanded_entities)\n",
        "expanded_entities.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY7xkv6bK6ZJ"
      },
      "source": [
        "Elimina as colunas que não têm utilidade para nossa análise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bMBwSQtKPuP"
      },
      "source": [
        "ignored_columns = ['symbols']\n",
        "expanded_entities.drop(columns=ignored_columns, inplace=True)\n",
        "expanded_entities.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TusDDJqM4_hC"
      },
      "source": [
        "Converte colunas contendo listas em representações string de objetos JSON:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37XIVEdD4910"
      },
      "source": [
        "converte_lista_json(expanded_entities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhGxZ4xpnJ6y"
      },
      "source": [
        "## Faz o Join desses datasets com o principal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_jQaTYndNpt"
      },
      "source": [
        "# Adiciona prefixo \"user_\" às colunas do DS \"expanded_user\" antes do join\n",
        "ds = ds.join(expanded_user.add_prefix('user_'))\n",
        "# Adiciona prefixo \"tweet_\" às colunas do DS \"expanded_ext_tweet\" antes do join\n",
        "ds = ds.join(expanded_ext_tweet.add_prefix('tweet_'))\n",
        "# Adiciona prefixo \"entities_\" às colunas do DS \"expanded_entities\" antes do join\n",
        "ds = ds.join(expanded_entities.add_prefix('entities_'))\n",
        "# Elimina as colunas JSON\n",
        "ds.drop(columns=['user', 'extended_tweet', 'entities'], inplace=True)\n",
        "ds.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbb8T_nPbmss"
      },
      "source": [
        "## Troca as colunas relativas ao tweet estendido quando o tamanho ultrapassa 140 caracteres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT5TANcATrdD"
      },
      "source": [
        "# Colunas referentes ao tweet original (140) e estendido (280)\n",
        "columns_140 = ['text', 'entities_hashtags', 'entities_urls', 'entities_user_mentions']\n",
        "columns_280 = ['tweet_full_text', 'tweet_entities.hashtags', 'tweet_entities.urls', 'tweet_entities.user_mentions']\n",
        "# Troca os valores das colunas originais pelos das colunas estendidas\n",
        "ds.loc[ds.truncated, columns_140] = ds.loc[ds.truncated, columns_280].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb5AuO62eoTm"
      },
      "source": [
        "## Elimina as colunas relativas ao tweet estendido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3z4JgKleQ_X"
      },
      "source": [
        "ds.drop(columns=columns_280, inplace=True)\n",
        "ds.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgh9kJqZwAHX"
      },
      "source": [
        "## Preenchimento de nulos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh8fTF_vqEEl"
      },
      "source": [
        "# Preenche campos texto com a string vazia\n",
        "ds['source'] = ds['source'].fillna('')\n",
        "ds['user_location'] = ds['user_location'].fillna('')\n",
        "ds['user_description'] = ds['user_description'].fillna('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lIdqrnb6Hgr"
      },
      "source": [
        "## Salva Dataset limpo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLiYemkgLfaq"
      },
      "source": [
        "# Parâmetro \"escapechar\" usado para lidar com quebra de linhas nos campos texto\n",
        "ds.to_csv('prefeito_rio_2020_clean.csv', index=False, escapechar='\\r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXy_4LXeaPxv"
      },
      "source": [
        "# Processamento de Texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es2GCCtwy0Pu"
      },
      "source": [
        "## Função de Tokenização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtM1Mb_xigK4"
      },
      "source": [
        "def clean_and_tokenize(text: str, entities_urls: list, language='portuguese', check_url=True):\n",
        "  texto = text\n",
        "  # Executa limpeza de urls no texto\n",
        "  if check_url:\n",
        "    for urls in entities_urls:\n",
        "      texto = texto.replace(urls.get('url'), '')\n",
        "  # Tokenização por palavras e limpeza de stopwords, pontuação e símbolos\n",
        "  palavras = tokenize.word_tokenize(texto.lower(), language)\n",
        "  stop_words = set(stopwords.words(language) + list(punctuation))\n",
        "  palavras_sem_stopwords = [palavra for palavra in palavras if palavra not in stop_words and re.search(\"\\w+\", palavra)]\n",
        "\n",
        "  return palavras_sem_stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14krb2Ni62fd"
      },
      "source": [
        "## Carrega strings JSON como objetos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-xU5VQ6zAox"
      },
      "source": [
        "ds.entities_hashtags = ds.entities_hashtags.apply(json.loads)\n",
        "ds.entities_urls = ds.entities_urls.apply(json.loads)\n",
        "ds.entities_user_mentions = ds.entities_user_mentions.apply(json.loads)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMfwKBUEHWEn"
      },
      "source": [
        "## Cria dataset tokenizado em português"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcD5mo7C-ZrX"
      },
      "source": [
        "ds_por = ds[ds.lang == 'pt']\n",
        "text_tokens = ds_por.apply(lambda row: clean_and_tokenize(row['text'], row['entities_urls']), axis=1)\n",
        "text_tokens.name = 'text_tokens'\n",
        "ds_por = ds_por.join(text_tokens)\n",
        "ds_por.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpPpoYbz61eV"
      },
      "source": [
        "### Tokeniza Descrição do Usuário"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALpzOz6_g1da"
      },
      "source": [
        "text_tokens = ds_por.user_description.apply(lambda row: clean_and_tokenize(row, [], check_url=False))\n",
        "text_tokens.name = 'user_description_tokens'\n",
        "ds_por = ds_por.join(text_tokens)\n",
        "ds_por.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDa5lxOcn_kl"
      },
      "source": [
        "### Salva Dataset em Português"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awf2KBcTodJE"
      },
      "source": [
        "# Parâmetro \"escapechar\" usado para lidar com quebra de linhas nos campos texto\n",
        "ds_por.to_csv('prefeito_rio_2020_pt.csv', escapechar='\\r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTGrChQ7-gNe"
      },
      "source": [
        "# TODO Análise Exploratória de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTI10JEaPQao"
      },
      "source": [
        "ds_ing = ds[ds.lang == 'en']\n",
        "ds_und = ds[ds.lang == 'und']\n",
        "ds_ing.head()\n",
        "ds_und.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxTkA-4rWXTb"
      },
      "source": [
        "ds['lang'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}